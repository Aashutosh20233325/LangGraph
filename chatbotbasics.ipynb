{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee71654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab35831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbb546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aba4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "\n",
    "def chat_node(state: ChatState):\n",
    "\n",
    "    # take user query from state\n",
    "    messages = state['messages']\n",
    "\n",
    "    # send to llm\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # response store state\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d436db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f358280",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# add nodes\n",
    "graph.add_node('chat_node', chat_node)\n",
    "\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_edge('chat_node', END)\n",
    "\n",
    "chatbot = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "052d0b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the capital of india', additional_kwargs={}, response_metadata={}, id='ff4eafcb-01e5-4e22-b93a-34faa4b39f48'),\n",
       "  AIMessage(content='The capital of India is **New\\u202fDelhi**.', additional_kwargs={'reasoning_content': 'The user asks: \"What is the capital of india\". Simple question. Answer: New Delhi. Provide brief answer.'}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 77, 'total_tokens': 122, 'completion_time': 0.094598692, 'completion_tokens_details': {'reasoning_tokens': 25}, 'prompt_time': 0.00301177, 'prompt_tokens_details': None, 'queue_time': 0.04933047, 'total_time': 0.097610462}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_e10890e4b9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b732c-ff98-7a61-9586-787358e81e1c-0', usage_metadata={'input_tokens': 77, 'output_tokens': 45, 'total_tokens': 122, 'output_token_details': {'reasoning': 25}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {\n",
    "    'messages': [HumanMessage(content='What is the capital of india')]\n",
    "}\n",
    "\n",
    "chatbot.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d265c755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='what are your capabilities', additional_kwargs={}, response_metadata={}, id='a78aeadb-b270-4b99-b913-98dbe77c471b'), AIMessage(content='I’m a versatile AI language model, and here’s a quick rundown of what I can do:\\n\\n### Core capabilities\\n| Category | What I can help with |\\n|----------|----------------------|\\n| **Conversation** | Carry on casual chats, answer questions, provide explanations, brainstorm ideas, or just keep you company. |\\n| **Information & Research** | Summarize articles, explain concepts, compare topics, give overviews of scientific, historical, technical, or cultural subjects. |\\n| **Writing & Editing** | Draft essays, reports, stories, poems, emails, marketing copy, scripts, and more. I can proofread, suggest style improvements, and adapt tone to your audience. |\\n| **Programming & Technical Tasks** | Write, debug, and explain code in many languages (Python, JavaScript, Java, C++, etc.), generate algorithms, create SQL queries, and help with software design or DevOps concepts. |\\n| **Mathematics & Data** | Solve arithmetic, algebra, calculus, statistics problems; explain steps; generate LaTeX; help interpret data visualizations. |\\n| **Language & Translation** | Translate between many languages, explain grammar, suggest phrasing, and help you learn a new language. |\\n| **Creative Work** | Produce stories, poems, jokes, riddles, game ideas, character bios, world‑building, and other imaginative content. |\\n| **Planning & Organization** | Build outlines, project plans, to‑do lists, itineraries, study schedules, or help structure presentations. |\\n| **Education & Tutoring** | Explain concepts at different difficulty levels, create practice problems, give feedback on student work, and simulate tutoring sessions. |\\n| **Accessibility** | Re‑phrase complex text into simpler language, generate alt‑text for images (based on descriptions), and help make content more inclusive. |\\n\\n### How I work\\n- **Context‑aware**: I keep track of the conversation thread (within the current session) to give coherent, relevant responses.\\n- **Multi‑turn reasoning**: I can break down complex problems step‑by‑step, ask clarifying questions, and refine answers iteratively.\\n- **Safety‑first**: I’m programmed to avoid providing disallowed content (e.g., illegal instructions, hate speech, personal data) and to flag or refuse unsafe requests.\\n\\n### Limitations to keep in mind\\n- **Knowledge cutoff**: My training data goes up to **June\\u202f2024**; I don’t have real‑time internet access, so I can’t fetch up‑to‑the‑minute news or browse the web.\\n- **Accuracy**: While I aim for factual correctness, I can still generate errors or outdated information. It’s always good to double‑check critical facts, especially for medical, legal, or financial matters.\\n- **No personal data**: I don’t store personal details between sessions, and I can’t retrieve private information about individuals unless you provide it in the conversation.\\n- **Creative liberties**: For artistic or speculative content, I may invent details (e.g., fictional backstories) that aren’t based on real sources.\\n\\nIf you have a specific task in mind, just let me know and I’ll dive in!', additional_kwargs={'reasoning_content': 'The user asks \"what are your capabilities\". We need to respond describing capabilities, as per policy. It\\'s allowed. Provide a concise overview: language understanding, generation, reasoning, code, math, summarization, translation, etc. Also mention limitations. Ensure not to violate any policy.'}, response_metadata={'token_usage': {'completion_tokens': 725, 'prompt_tokens': 75, 'total_tokens': 800, 'completion_time': 1.528347973, 'completion_tokens_details': {'reasoning_tokens': 58}, 'prompt_time': 0.002911145, 'prompt_tokens_details': None, 'queue_time': 0.054587935, 'total_time': 1.531259118}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_626f3fc5e0', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b732d-6137-7ee1-9b4a-53a18a3a9425-0', usage_metadata={'input_tokens': 75, 'output_tokens': 725, 'total_tokens': 800, 'output_token_details': {'reasoning': 58}})]}\n",
      "Exiting chat.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  user_message = input(\"You: \")\n",
    "\n",
    "  if user_message.lower() in ['exit', 'quit']:\n",
    "      print(\"Exiting chat.\")\n",
    "      break\n",
    "  response = chatbot.invoke({\n",
    "      'messages': [HumanMessage(content=user_message)]})\n",
    "  print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
